{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !which python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-1.2.3-py3-none-any.whl (520 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 520 kB 4.4 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting hf-xet<2.0.0,>=1.2.0\n",
            "  Downloading hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.7 MB 31.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting shellingham\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Collecting httpx<1,>=0.23.0\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 73 kB 9.3 MB/s  eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /Users/sana/Desktop/github repossss/Datascience_Projects/copilot-agent-project/dementia_prediction/.venv/lib/python3.9/site-packages (from huggingface-hub) (4.15.0)\n",
            "Collecting filelock\n",
            "  Downloading filelock-3.19.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: packaging>=20.9 in /Users/sana/Desktop/github repossss/Datascience_Projects/copilot-agent-project/dementia_prediction/.venv/lib/python3.9/site-packages (from huggingface-hub) (25.0)\n",
            "Collecting fsspec>=2023.5.0\n",
            "  Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200 kB 27.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tqdm>=4.42.1\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78 kB 26.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting typer-slim\n",
            "  Downloading typer_slim-0.21.0-py3-none-any.whl (47 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47 kB 9.9 MB/s  eta 0:00:01\n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading pyyaml-6.0.3-cp39-cp39-macosx_11_0_arm64.whl (174 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 174 kB 20.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting idna\n",
            "  Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71 kB 18.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting certifi\n",
            "  Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 159 kB 21.1 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting anyio\n",
            "  Downloading anyio-4.12.0-py3-none-any.whl (113 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 113 kB 21.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting httpcore==1.*\n",
            "  Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 78 kB 28.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting h11>=0.16\n",
            "  Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/sana/Desktop/github repossss/Datascience_Projects/copilot-agent-project/dementia_prediction/.venv/lib/python3.9/site-packages (from anyio->httpx<1,>=0.23.0->huggingface-hub) (1.3.0)\n",
            "Collecting click>=8.0.0\n",
            "  Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 98 kB 16.9 MB/s eta 0:00:01\n",
            "\u001b[?25hInstalling collected packages: idna, h11, certifi, httpcore, click, anyio, typer-slim, tqdm, shellingham, pyyaml, httpx, hf-xet, fsspec, filelock, huggingface-hub\n",
            "Successfully installed anyio-4.12.0 certifi-2025.11.12 click-8.1.8 filelock-3.19.1 fsspec-2025.10.0 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-1.2.3 idna-3.11 pyyaml-6.0.3 shellingham-1.5.4 tqdm-4.67.1 typer-slim-0.21.0\n",
            "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.3 is available.\n",
            "You should consider upgrading via the '/Users/sana/Desktop/github repossss/Datascience_Projects/copilot-agent-project/dementia_prediction/.venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install huggingface-hub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hugging Face debug notebook (ask-my-health)\n",
        "\n",
        "This notebook is for debugging Hugging Face connectivity *outside* the Streamlit app.\n",
        "\n",
        "## What it does\n",
        "\n",
        "1. Confirms your `HF_TOKEN` is valid (via `huggingface.co/api/whoami-v2`).\n",
        "2. Probes a few likely Hugging Face Router endpoints for a **single model**.\n",
        "3. Sends a **text-to-SQL prompt** and prints:\n",
        "   - HTTP status code\n",
        "   - response body (truncated)\n",
        "   - parsed JSON (if any)\n",
        "\n",
        "## Setup\n",
        "\n",
        "Set your token in the same environment where you run Jupyter:\n",
        "\n",
        "```bash\n",
        "export HF_TOKEN=\"hf_...\"\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ChatCompletionOutputMessage(role='assistant', content='The capital of France is **Paris**. ðŸ‡«ðŸ‡·', reasoning=None, tool_call_id=None, tool_calls=None)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "# Get token from environment variable - DO NOT hardcode tokens in notebooks!\n",
        "# Set it before running: export HF_TOKEN='hf_your_token_here'\n",
        "HF_TOKEN = os.getenv('HF_TOKEN')\n",
        "if not HF_TOKEN:\n",
        "    raise ValueError(\n",
        "        \"HF_TOKEN environment variable not set! \"\n",
        "        \"Set it with: export HF_TOKEN='hf_your_token_here' \"\n",
        "        \"Get your token from: https://huggingface.co/settings/tokens\"\n",
        "    )\n",
        "\n",
        "if not HF_TOKEN.startswith('hf_'):\n",
        "    raise ValueError(\n",
        "        f\"Invalid token format. Token must start with 'hf_'. \"\n",
        "        f\"Your token starts with: '{HF_TOKEN[:3]}'\"\n",
        "    )\n",
        "\n",
        "print(f\"âœ“ Using HF_TOKEN from environment (starts with: {HF_TOKEN[:10]}...)\")\n",
        "\n",
        "client = InferenceClient(\n",
        "    api_key=HF_TOKEN,\n",
        ")\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"deepseek-ai/DeepSeek-V3.2:novita\",\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"What is the capital of France?\"\n",
        "        }\n",
        "    ],\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SELECT COALESCE(SUM(steps), 0) AS answer FROM daily_steps WHERE date >= DATE_TRUNC('month', CURRENT_DATE) AND date < DATE_TRUNC('month', CURRENT_DATE) + INTERVAL 1 MONTH;\n"
          ]
        }
      ],
      "source": [
        "schema = \"daily_steps(date DATE, steps BIGINT)\"\n",
        "question = \"How many steps did I walk this month?\"\n",
        "\n",
        "prompt = f\"\"\"\n",
        "You are an expert at writing DuckDB SQL.\n",
        "\n",
        "Return ONLY a single SQL query (no explanations, no markdown).\n",
        "Rules:\n",
        "- Must be a single SELECT statement.\n",
        "- Query only the table {schema}.\n",
        "- Do not use any other tables.\n",
        "- If the question asks for a single number, return exactly one row with column alias answer.\n",
        "\n",
        "Question: {question}\n",
        "SQL:\n",
        "\"\"\".strip()\n",
        "\n",
        "completion = client.chat.completions.create(\n",
        "    model=\"deepseek-ai/DeepSeek-V3.2:novita\",\n",
        "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv (3.9.6)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
